{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline\n",
    "\n",
    "# Goal\n",
    "Create a data pipeline for the Census and Covid-19\n",
    "\n",
    "# Methodology\n",
    "- Clean the data with the foundings in Exploration notebooks\n",
    "- Concatenate and create the complete dataset for census data. This will be one dataset available on S3.\n",
    "- This data may be upload to Redshift to do different queries.\n",
    "\n",
    "As the COVID data is found by city we are going to do multiple aggregations for each city\n",
    "- Range ages by city\n",
    "- Gender proportion by city\n",
    "- People by city\n",
    "- Adequate access to public services by city\n",
    "- Internet services by city\n",
    "- Health quality service by city\n",
    "- Life expectancy by city\n",
    "\n",
    "The idea is to combine the COVID data with the census which is how the city sii and get proportion acording to the particularities of each to estimate mortality rates by city, vulnerable cities, \"older\" cities, connection between health services and covid deaths, internet as a proxy of information about covid and some things like that, changes in life expectancy.\n",
    "\n",
    "## Sections\n",
    "1. [**Requirements**](#Requirements)\n",
    "2. [**Functions**](#Functions)\n",
    "3. [**Inputs**](#Inputs)\n",
    "4. [**Pipeline**](#Pipeline)\n",
    "    - [**Indicators**](#Indicators)\n",
    "    - [**Intention_features**](#Intention_features)\n",
    "    - [**TopicEncodings**](#TopicEncodings)\n",
    "    - [**EngagingFollowsEngaged**](#EngagingFollowsEngaged)\n",
    "    - [**Hashtags**](#Hashtags)\n",
    "    - [**Domain**](#Domain)\n",
    "    - [**Language**](#Language)\n",
    "    - [**Media**](#Media)\n",
    "    - [**Links**](#Links)\n",
    "    - [**Tweet_type**](#Tweet_type)\n",
    "    - [**Timestamp_features**](#Timestamp_features)\n",
    "    - [**Followers_and_Followings_features**](#Followers_and_Followings_features)\n",
    "    - [**Quantile_Discretizer**](#Quantile_Discretizer)\n",
    "    - [**Intentions_join**](#Intentions_join)\n",
    "5. [**FeatureSelection**](#FeatureSelection)\n",
    "6. [**Imputation**](#Imputation)\n",
    "7. [**Validation**](#Validation)\n",
    "8. [**Saving_df**](#Saving_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ad4b84c16f40399790e497be7d6fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>1</td><td>application_1591125667695_0002</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-2-159.us-west-2.compute.internal:20888/proxy/application_1591125667695_0002/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-9-181.us-west-2.compute.internal:8042/node/containerlogs/container_1591125667695_0002_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-1.0.4-cp36-cp36m-manylinux1_x86_64.whl (10.1 MB)\n",
      "Collecting python-dateutil>=2.6.1\n",
      "  Using cached python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib64/python3.6/site-packages (from pandas) (1.14.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas) (1.13.0)\n",
      "Installing collected packages: python-dateutil, pandas\n",
      "Successfully installed pandas-1.0.4 python-dateutil-2.8.1\n",
      "\n",
      "Collecting boto3\n",
      "  Using cached boto3-1.13.21-py2.py3-none-any.whl (128 kB)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0\n",
      "  Using cached s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n",
      "Collecting botocore<1.17.0,>=1.16.21\n",
      "  Using cached botocore-1.16.21-py2.py3-none-any.whl (6.2 MB)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/site-packages (from boto3) (0.9.4)\n",
      "Collecting docutils<0.16,>=0.10\n",
      "  Using cached docutils-0.15.2-py3-none-any.whl (547 kB)\n",
      "Collecting urllib3<1.26,>=1.20; python_version != \"3.4\"\n",
      "  Using cached urllib3-1.25.9-py2.py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /mnt/tmp/1591134876738-0/lib/python3.6/site-packages (from botocore<1.17.0,>=1.16.21->boto3) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.17.0,>=1.16.21->boto3) (1.13.0)\n",
      "Installing collected packages: docutils, urllib3, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.13.21 botocore-1.16.21 docutils-0.15.2 s3transfer-0.3.3 urllib3-1.25.9"
     ]
    }
   ],
   "source": [
    "#installing packages\n",
    "sc.install_pypi_package(\"pandas\")\n",
    "sc.install_pypi_package(\"boto3\")\n",
    "sc.setCheckpointDir('hdfs:///covid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a529daef9c6949c790563ac7ada11c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048M\n",
      "1000"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import boto3\n",
    "import gc\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (FloatType, DateType, StructType, StructField, StringType, LongType, \n",
    "    IntegerType, ArrayType, BooleanType, DoubleType)\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, QuantileDiscretizer\n",
    "gc.enable()\n",
    "\n",
    "spark = SparkSession.builder.config(\"spark.sql.shuffle.partitions\", 200).appName(\"covid\").getOrCreate()\n",
    "print(spark.sparkContext.getConf().get('spark.driver.memory'))\n",
    "print(spark.sparkContext.getConf().get(\"spark.sql.shuffle.partitions\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc31304dbb144fb8e0d1e007b5eff63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_schema_census(source=\"vivienda\"):\n",
    "    \"\"\"\n",
    "    Build schema for different sources\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    source : str\n",
    "        Table source may be: \"VIV\", \"PER\", \"HOG\", \"FALL\", \"MGN\"\n",
    "\n",
    "    Return:\n",
    "    -------\n",
    "    schema : spark.schema\n",
    "        Spark schema for loading source table\n",
    "    \"\"\"\n",
    "    if source == \"VIV\":\n",
    "        schema = StructType([StructField(\"TIPO_REG\", IntegerType()),\n",
    "                             StructField(\"U_DPTO\", IntegerType()),\n",
    "                             StructField(\"U_MPIO\", IntegerType()),\n",
    "                             StructField(\"UA_CLASE\", IntegerType()),\n",
    "                             StructField(\"U_EDIFICA\", IntegerType()),\n",
    "                             StructField(\"COD_ENCUESTAS\", IntegerType()),\n",
    "                             StructField(\"U_VIVIENDA\", IntegerType()),\n",
    "                             StructField(\"UVA_ESTATER\", IntegerType()),\n",
    "                             StructField(\"UVA1_TIPOTER\", LongType()),\n",
    "                             StructField(\"UVA2_CODTER\", LongType()),\n",
    "                             StructField(\"UVA_ESTA_AREAPROT\", IntegerType()),\n",
    "                             StructField(\"UVA1_COD_AREAPROT\", LongType()),\n",
    "                             StructField(\"UVA_USO_UNIDAD\", IntegerType()),\n",
    "                             StructField(\"V_TIPO_VIV\", LongType()),\n",
    "                             StructField(\"V_CON_OCUP\", LongType()),\n",
    "                             StructField(\"V_TOT_HOG\", LongType()),\n",
    "                             StructField(\"V_MAT_PARED\", LongType()),\n",
    "                             StructField(\"V_MAT_PISO\", LongType()),\n",
    "                             StructField(\"VA_EE\", LongType()),\n",
    "                             StructField(\"VA1_ESTRATO\", LongType()),\n",
    "                             StructField(\"VB_ACU\", LongType()),\n",
    "                             StructField(\"VC_ALC\", LongType()),\n",
    "                             StructField(\"VD_GAS\", LongType()),\n",
    "                             StructField(\"VE_RECBAS\", LongType()),\n",
    "                             StructField(\"VE1_QSEM\", LongType()),\n",
    "                             StructField(\"VF_INTERNET\", LongType()),\n",
    "                             StructField(\"V_TIPO_SERSA\", LongType()),\n",
    "                             StructField(\"L_TIPO_INST\", LongType()),\n",
    "                             StructField(\"L_EXISTEHOG\", LongType()),\n",
    "                             StructField(\"L_TOT_PERL\", LongType())\n",
    "                             ])\n",
    "    elif source == \"HOG\":\n",
    "        schema = StructType([StructField(\"TIPO_REG\", IntegerType()),\n",
    "                             StructField(\"U_DPTO\", IntegerType()),\n",
    "                             StructField(\"U_MPIO\", IntegerType()),\n",
    "                             StructField(\"UA_CLASE\", IntegerType()),\n",
    "                             StructField(\"COD_ENCUESTAS\", IntegerType()),\n",
    "                             StructField(\"U_VIVIENDA\", IntegerType()),\n",
    "                             StructField(\"H_NROHOG\", LongType()),\n",
    "                             StructField(\"H_NRO_CUARTOS\", LongType()),\n",
    "                             StructField(\"H_NRO_DORMIT\", LongType()),\n",
    "                             StructField(\"H_DONDE_PREPALIM\", LongType()),\n",
    "                             StructField(\"H_AGUA_COCIN\", LongType()),\n",
    "                             StructField(\"HA_NRO_FALL\", LongType()),\n",
    "                             StructField(\"HA_TOT_PER\", LongType())\n",
    "                             ])\n",
    "    elif source == \"PER\":\n",
    "        schema = StructType([StructField(\"TIPO_REG\", IntegerType()),\n",
    "                             StructField(\"U_DPTO\", IntegerType()),\n",
    "                             StructField(\"U_MPIO\", IntegerType()),\n",
    "                             StructField(\"UA_CLASE\", IntegerType()),\n",
    "                             StructField(\"U_EDIFICA\", IntegerType()),\n",
    "                             StructField(\"COD_ENCUESTAS\", IntegerType()),\n",
    "                             StructField(\"U_VIVIENDA\", IntegerType()),\n",
    "                             StructField(\"P_NROHOG\", LongType()),\n",
    "                             StructField(\"P_NRO_PER\", IntegerType()),\n",
    "                             StructField(\"P_SEXO\", IntegerType()),\n",
    "                             StructField(\"P_EDADR\", IntegerType()),\n",
    "                             StructField(\"P_PARENTESCOR\", LongType()),\n",
    "                             StructField(\"PA1_GRP_ETNIC\", IntegerType()),\n",
    "                             StructField(\"PA11_COD_ETNIA\", LongType()),\n",
    "                             StructField(\"PA12_CLAN\", LongType()),\n",
    "                             StructField(\"PA21_COD_VITSA\", LongType()),\n",
    "                             StructField(\"PA22_COD_KUMPA\", LongType()),\n",
    "                             StructField(\"PA_HABLA_LENG\", LongType()),\n",
    "                             StructField(\"PA1_ENTIENDE\", LongType()),\n",
    "                             StructField(\"PB_OTRAS_LENG\", LongType()),\n",
    "                             StructField(\"PB1_QOTRAS_LENG\", LongType()),\n",
    "                             StructField(\"PA_LUG_NAC\", IntegerType()),\n",
    "                             StructField(\"PA_VIVIA_5ANOS\", LongType()),\n",
    "                             StructField(\"PA_VIVIA_1ANO\", LongType()),\n",
    "                             StructField(\"P_ENFERMO\", LongType()),\n",
    "                             StructField(\"P_QUEHIZO_PPAL\", LongType()),\n",
    "                             StructField(\"PA_LO_ATENDIERON\", LongType()),\n",
    "                             StructField(\"PA1_CALIDAD_SERV\", LongType()),\n",
    "                             StructField(\"CONDICION_FISICA\", LongType()),\n",
    "                             StructField(\"P_ALFABETA\", LongType()),\n",
    "                             StructField(\"PA_ASISTENCIA\", LongType()),\n",
    "                             StructField(\"P_NIVEL_ANOSR\", LongType()),\n",
    "                             StructField(\"P_TRABAJO\", LongType()),\n",
    "                             StructField(\"P_EST_CIVIL\", LongType()),\n",
    "                             StructField(\"PA_HNV\", LongType()),\n",
    "                             StructField(\"PA1_THNV\", LongType()),\n",
    "                             StructField(\"PA2_HNVH\", LongType()),\n",
    "                             StructField(\"PA3_HNVM\", LongType()),\n",
    "                             StructField(\"PA_HNVS\", LongType()),\n",
    "                             StructField(\"PA1_THSV\", LongType()),\n",
    "                             StructField(\"PA2_HSVH\", LongType()),\n",
    "                             StructField(\"PA3_HSVM\", LongType()),\n",
    "                             StructField(\"PA_HFC\", LongType()),\n",
    "                             StructField(\"PA1_THFC\", LongType()),\n",
    "                             StructField(\"PA2_HFCH\", LongType()),\n",
    "                             StructField(\"PA3_HFCM\", LongType()),\n",
    "                             StructField(\"PA_UHNV\", LongType()),\n",
    "                             StructField(\"PA1_MES_UHNV\", LongType()),\n",
    "                             StructField(\"PA2_ANO_UHNV\", LongType())\n",
    "                             ])\n",
    "    elif source == \"FALL\":\n",
    "        schema = StructType([StructField(\"TIPO_REG\", IntegerType()),\n",
    "                             StructField(\"U_DPTO\", IntegerType()),\n",
    "                             StructField(\"U_MPIO\", IntegerType()),\n",
    "                             StructField(\"UA_CLASE\", IntegerType()),\n",
    "                             StructField(\"COD_ENCUESTAS\", IntegerType()),\n",
    "                             StructField(\"U_VIVIENDA\", IntegerType()),\n",
    "                             StructField(\"F_NROHOG\", IntegerType()),\n",
    "                             StructField(\"FA1_NRO_FALL\", IntegerType()),\n",
    "                             StructField(\"FA2_SEXO_FALL\", IntegerType()),\n",
    "                             StructField(\"FA3_EDAD_FALL\", IntegerType()),\n",
    "                             StructField(\"FA4_CERT_DEFUN\", IntegerType())\n",
    "                             ])\n",
    "    elif source == \"MGN\":\n",
    "        schema = StructType([StructField(\"U_DPTO\", IntegerType()),\n",
    "                             StructField(\"U_MPIO\", IntegerType()),\n",
    "                             StructField(\"UA_CLASE\", IntegerType()),\n",
    "                             StructField(\"UA1_LOCALIDAD\", IntegerType()),\n",
    "                             StructField(\"U_SECT_RUR\", IntegerType()),\n",
    "                             StructField(\"U_SECC_RUR\", IntegerType()),\n",
    "                             StructField(\"UA2_CPOB\", IntegerType()),\n",
    "                             StructField(\"U_SECT_URB\", IntegerType()),\n",
    "                             StructField(\"U_SECC_URB\", IntegerType()),\n",
    "                             StructField(\"U_MZA\", IntegerType()),\n",
    "                             StructField(\"U_EDIFICA\", IntegerType()),\n",
    "                             StructField(\"COD_ENCUESTAS\", IntegerType()),\n",
    "                             StructField(\"U_VIVIENDA\", IntegerType())\n",
    "                             ])\n",
    "    else:\n",
    "        print(\"Source not valid. Enter one of the following sources: VIV, PER, HOG, FALL, MGN\")\n",
    "    return schema\n",
    "\n",
    "\n",
    "def build_schema_covid(source=\"covid\"):\n",
    "    \"\"\"\n",
    "    Build schema for different covid sources\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    source : str\n",
    "        Table source may be: \"covid\", \"tests\"\n",
    "\n",
    "    Return:\n",
    "    -------\n",
    "    schema : spark.schema\n",
    "        Spark schema for loading source table\n",
    "    \"\"\"\n",
    "    if source == \"covid\":\n",
    "        schema = StructType([StructField(\"fecha_de_notificaci_n\", DateType()),\n",
    "                             StructField(\"c_digo_divipola\", StringType()),\n",
    "                             StructField(\"ciudad_de_ubicaci_n\", StringType()),\n",
    "                             StructField(\"departamento\", StringType()),\n",
    "                             StructField(\"atenci_n\", StringType()),\n",
    "                             StructField(\"edad\", IntegerType()),\n",
    "                             StructField(\"sexo\", StringType()),\n",
    "                             StructField(\"tipo\", StringType()),\n",
    "                             StructField(\"estado\", StringType()),\n",
    "                             StructField(\"pa_s_de_procedencia\", StringType()),\n",
    "                             StructField(\"fis\", DateType()),\n",
    "                             StructField(\"fecha_diagnostico\", DateType()),\n",
    "                             StructField(\"fecha_recuperado\", DateType()),\n",
    "                             StructField(\"fecha_reporte_web\", DateType()),\n",
    "                             StructField(\"tipo_recuperaci_n\", StringType()),\n",
    "                             StructField(\"codigo_departamento\", StringType()),\n",
    "                             StructField(\"codigo_pais\", StringType()),\n",
    "                             StructField(\"pertenencia_etnica\", StringType()),\n",
    "                             StructField(\"nombre_grupo_etnico\", StringType()),\n",
    "                             StructField(\"fecha_de_muerte\", DateType()),\n",
    "                             StructField(\"Asintomatico\", IntegerType()),\n",
    "                             StructField(\"divipola_dpto\", IntegerType()),\n",
    "                             StructField(\"divipola_mpio\", IntegerType())\n",
    "                             ])\n",
    "    elif source == \"tests\":\n",
    "        schema = StructType([StructField(\"fecha\", DateType()),\n",
    "                             StructField(\"acumuladas\", LongType()),\n",
    "                             StructField(\"amazonas\", LongType()),\n",
    "                             StructField(\"antioquia\", LongType()),\n",
    "                             StructField(\"arauca\", LongType()),\n",
    "                             StructField(\"atlantico\", LongType()),\n",
    "                             StructField(\"bogota\", LongType()),\n",
    "                             StructField(\"bolivar\", LongType()),\n",
    "                             StructField(\"boyaca\", LongType()),\n",
    "                             StructField(\"caldas\", LongType()),\n",
    "                             StructField(\"caqueta\", LongType()),\n",
    "                             StructField(\"casanare\", LongType()),\n",
    "                             StructField(\"cauca\", LongType()),\n",
    "                             StructField(\"cesar\", LongType()),\n",
    "                             StructField(\"choco\", LongType()),\n",
    "                             StructField(\"cordoba\", LongType()),\n",
    "                             StructField(\"cundinamarca\", LongType()),\n",
    "                             StructField(\"guainia\", LongType()),\n",
    "                             StructField(\"guajira\", LongType()),\n",
    "                             StructField(\"guaviare\", LongType()),\n",
    "                             StructField(\"huila\", LongType()),\n",
    "                             StructField(\"magdalena\", LongType()),\n",
    "                             StructField(\"meta\", LongType()),\n",
    "                             StructField(\"narino\", LongType()),\n",
    "                             StructField(\"norte_de_santander\", LongType()),\n",
    "                             StructField(\"putumayo\", LongType()),\n",
    "                             StructField(\"quindio\", LongType()),\n",
    "                             StructField(\"risaralda\", LongType()),\n",
    "                             StructField(\"san_andres\", LongType()),\n",
    "                             StructField(\"santander\", LongType()),\n",
    "                             StructField(\"sucre\", LongType()),\n",
    "                             StructField(\"tolima\", LongType()),\n",
    "                             StructField(\"valle_del_cauca\", LongType()),\n",
    "                             StructField(\"vaupes\", LongType()),\n",
    "                             StructField(\"vichada\", LongType()),\n",
    "                             StructField(\"procedencia_desconocida\", LongType()),\n",
    "                             StructField(\"positivas_acumuladas\", LongType()),\n",
    "                             StructField(\"negativas_acumuladas\", LongType()),\n",
    "                             StructField(\"positividad_acumulada\", LongType()),\n",
    "                             StructField(\"indeterminadas\", LongType()),\n",
    "                             StructField(\"barranquilla\", LongType()),\n",
    "                             StructField(\"cartagena\", LongType()),\n",
    "                             StructField(\"santa_marta\", LongType())\n",
    "                             ])\n",
    "    else:\n",
    "        print(\"Source not valid. Enter one of the following sources: 'covid', 'tests'\")\n",
    "    return schema\n",
    "              \n",
    "def build_schema_divipola(source=\"divipola\"):\n",
    "    \"\"\"\n",
    "    Build schema for different covid sources\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    source : str\n",
    "        Table source may be: \"covid\", \"tests\"\n",
    "\n",
    "    Return:\n",
    "    -------\n",
    "    schema : spark.schema\n",
    "        Spark schema for loading source table\n",
    "    \"\"\"\n",
    "    if source == \"divipola\":\n",
    "        schema = StructType([StructField(\"cod_depto\", IntegerType()),\n",
    "                             StructField(\"cod_mpio\", IntegerType()),\n",
    "                             StructField(\"dpto\", StringType()),\n",
    "                             StructField(\"nom_mpio\", StringType()),\n",
    "                             StructField(\"tipo_municipio\", StringType())\n",
    "                             ])\n",
    "    else:\n",
    "        print(\"Source not valid. Enter one of the following sources: 'covid', 'tests'\")\n",
    "    return schema\n",
    "              \n",
    "def get_censo_paths(bucket_s3, directory_key):\n",
    "    \"\"\"\n",
    "    Get dictionary of census data for each department\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    bucket_s3 : s3.Bucket\n",
    "        Boto3 Bucket object\n",
    "    directory_key : path\n",
    "        Directory key in S3\n",
    "    \n",
    "    Return:\n",
    "    -------\n",
    "    dict_paths_departments : dict\n",
    "        Dictionary with the data path for each departtment\n",
    "    \"\"\"\n",
    "    dict_paths_departments = {}\n",
    "    for object_summary in bucket_s3.objects.filter(Prefix=directory_key):\n",
    "        name = object_summary.key\n",
    "        if name.endswith(\".CSV\"):\n",
    "            list_paths = name.split(\"/\")\n",
    "            department = list_paths[2].split(\"_\")[1]\n",
    "            if \"MGN\" in list_paths[-1]:\n",
    "                if not(department in dict_paths_departments):\n",
    "                    dict_paths_departments[department] = {}\n",
    "                dict_paths_departments[department].update({\"MGN\": os.path.join(f\"s3a://{bucket_s3.name}\", name)})                \n",
    "            elif \"FALL\" in list_paths[-1]:\n",
    "                if not(department in dict_paths_departments):\n",
    "                    dict_paths_departments[department] = {}\n",
    "                dict_paths_departments[department].update({\"FALL\": os.path.join(f\"s3a://{bucket_s3.name}\", name)})\n",
    "            elif \"HOG\" in list_paths[-1]:\n",
    "                if not(department in dict_paths_departments):\n",
    "                    dict_paths_departments[department] = {}\n",
    "                dict_paths_departments[department].update({\"HOG\": os.path.join(f\"s3a://{bucket_s3.name}\", name)})\n",
    "            elif \"VIV\" in list_paths[-1]:\n",
    "                if not(department in dict_paths_departments):\n",
    "                    dict_paths_departments[department] = {}\n",
    "                dict_paths_departments[department].update({\"VIV\": os.path.join(f\"s3a://{bucket_s3.name}\", name)})\n",
    "            elif \"PER\" in list_paths[-1]:\n",
    "                if not(department in dict_paths_departments):\n",
    "                    dict_paths_departments[department] = {}\n",
    "                dict_paths_departments[department].update({\"PER\": os.path.join(f\"s3a://{bucket_s3.name}\", name)})\n",
    "    return dict_paths_departments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f525c2beb8402ebaa9b68de0310db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def mediaCounter(row, media='Photo'):\n",
    "    counter=0\n",
    "    if type(row)==list:\n",
    "        for elem in row:\n",
    "            if elem==media:\n",
    "                counter+=1\n",
    "    else:\n",
    "        pass\n",
    "    return counter\n",
    "\n",
    "def listCounter(row):\n",
    "    counter=0\n",
    "    if type(row)==list:\n",
    "        counter+=len(row)\n",
    "    else:\n",
    "        pass\n",
    "    return counter\n",
    "\n",
    "def labelEncoder(row, mapping_encode):\n",
    "    \"\"\"\n",
    "    Label Encoding or Array<String> types\n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    row : list(string)\n",
    "        List of string or labels\n",
    "    mapping_encode : dict(label, integer)\n",
    "        Encoding of some top K labels\n",
    "    Return:\n",
    "    -------\n",
    "    out : list(integers)\n",
    "        List of Label Encoders.\n",
    "        if not in mapping Encoded to len(map)\n",
    "        if not a list Encoded to len(map)+1\n",
    "    \"\"\"\n",
    "    out=[]\n",
    "    if type(row)==list:\n",
    "        for elem in row:\n",
    "            if elem in mapping_encode:\n",
    "                out.append(mapping_encode.get(elem))\n",
    "            else:\n",
    "                out.append(len(mapping_encode))\n",
    "    else:\n",
    "        out.append(len(mapping_encode)+1)\n",
    "    return out\n",
    "\n",
    "def labelEncoderSingle(row, mapping_encode):\n",
    "    out=[]\n",
    "    if row:\n",
    "        if row in mapping_encode:\n",
    "            out.append(mapping_encode.get(row))\n",
    "        else:\n",
    "            out.append(len(mapping_encode))\n",
    "    else:\n",
    "        out.append(len(mapping_encode)+1)\n",
    "    return out\n",
    "\n",
    "def hashtagSumCounter(row, mapping_hashtag_count):\n",
    "    counter=0\n",
    "    if type(row)==list:\n",
    "        for elem in row:\n",
    "            if elem in mapping_hashtag_count:\n",
    "                counter+=mapping_hashtag_count.get(elem, 0)\n",
    "    else:\n",
    "        pass\n",
    "    return counter\n",
    "\n",
    "def get_distribution_array_col(df, col):\n",
    "    distribution_df = df.select(col).filter(F.col(col).isNotNull())\\\n",
    "                              .withColumn(col, \n",
    "                                          F.explode(F.col(col)))\\\n",
    "                              .groupBy(col).count()\\\n",
    "                              .orderBy(F.col(\"count\").desc())\n",
    "    return distribution_df\n",
    "\n",
    "def save_pkl_to_s3(obj, key_filename, bucket_name):\n",
    "    serialized_obj = pickle.dumps(obj)\n",
    "    s3 = boto3.client('s3')\n",
    "    s3.put_object(Bucket=bucket_name, Key=key_filename, \n",
    "                  Body=serialized_obj)\n",
    "    \n",
    "def columns2cast(df):\n",
    "    columns = []\n",
    "    for col in df.schema:\n",
    "        if col.dataType.typeName()==\"array\":\n",
    "            columns.append(col)\n",
    "    return columns\n",
    "    \n",
    "def cast_array2string(df, columns):\n",
    "    for col in columns:\n",
    "        df = df.withColumn(col.name, F.col(col.name).cast(StringType()))\n",
    "    return df\n",
    "\n",
    "def cast_string2array(df, columns):\n",
    "    for col in columns:\n",
    "        df= df.withColumn(col, \n",
    "                          F.split(F.regexp_replace(F.col(col), r\"(^\\[)|(\\]$)|(')\", \"\"),\n",
    "                                  \", \"))\n",
    "    return df\n",
    "    \n",
    "def mappings(df, col, top_k):\n",
    "    col_dist = get_distribution_array_col(df, col)\n",
    "    df_col_dist = col_dist.limit(top_k)\n",
    "    df_col = df_col_dist.toPandas().rename(columns={'_1': col, \n",
    "                                                    '_2': 'count'})\\\n",
    "                                    .reset_index().set_index(col)\n",
    "    mapping_encode = df_col['index'].to_dict()\n",
    "    mapping_count = df_col['count'].to_dict()\n",
    "    return mapping_encode, mapping_count\n",
    "\n",
    "def mapping_label_encoder(df, col, top_k):\n",
    "    col_dist = df.select(col).filter(F.col(col).isNotNull())\\\n",
    "                      .groupBy(col).count()\\\n",
    "                      .orderBy(F.col(\"count\").desc())\n",
    "    df_col_dist = col_dist.limit(top_k)\n",
    "    df_col = df_col_dist.toPandas().rename(columns={'_1': col, \n",
    "                                                    '_2': 'count'})\\\n",
    "                                    .reset_index().set_index(col)\n",
    "    mapping_encoder = df_col['index'].to_dict()\n",
    "    return mapping_encoder\n",
    "\n",
    "def validator(df):\n",
    "    columns_w_nan = {}\n",
    "    for col in df.schema:\n",
    "        null_count = df.filter(F.col(col.name).isNull()).count()\n",
    "        if null_count>0:\n",
    "            columns_w_nan[col.name]=null_count\n",
    "    return columns_w_nan\n",
    "\n",
    "# Mappings\n",
    "tweet_type_mapping = {'TopLevel':0, 'Quote':1, 'Retweet':2, 'Reply':3}\n",
    "\n",
    "# UDF SQL\n",
    "PhotoCounter_udf = F.udf(lambda row: mediaCounter(row, 'Photo'), \n",
    "                         IntegerType())\n",
    "VideoCounter_udf = F.udf(lambda row: mediaCounter(row, 'Video'), \n",
    "                         IntegerType())\n",
    "GifCounter_udf = F.udf(lambda row: mediaCounter(row, 'GIF'), \n",
    "                         IntegerType())\n",
    "listCounter_udf = F.udf(listCounter, \n",
    "                         IntegerType())\n",
    "tweet_encoded_udf = F.udf(lambda x: tweet_type_mapping[x], \n",
    "                             IntegerType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b723449397b04abc992c72004b89a363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata = {\"CENSO\": {\"VIVIENDA\": {\"useful_columns\": ['U_DPTO', 'U_MPIO', 'UA_CLASE', 'U_EDIFICA',\n",
    "                                                      'COD_ENCUESTAS', 'U_VIVIENDA', 'UVA_USO_UNIDAD',\n",
    "                                                      'V_TIPO_VIV', 'V_CON_OCUP', 'V_TOT_HOG',\n",
    "                                                      'V_MAT_PARED', 'V_MAT_PISO', 'VA_EE', 'VA1_ESTRATO', 'VB_ACU', 'VC_ALC',\n",
    "                                                      'VD_GAS', 'VE_RECBAS', 'VE1_QSEM', 'VF_INTERNET', 'V_TIPO_SERSA',\n",
    "                                                      'L_TIPO_INST', 'L_EXISTEHOG', 'L_TOT_PERL']\n",
    "                                   },\n",
    "                      \"HOGAR\": {\"useful_columns\": ['U_DPTO', 'U_MPIO', 'UA_CLASE', 'COD_ENCUESTAS',\n",
    "                                                   'U_VIVIENDA', 'H_NROHOG', 'H_NRO_CUARTOS', 'H_NRO_DORMIT',\n",
    "                                                   'H_DONDE_PREPALIM', 'H_AGUA_COCIN', 'HA_NRO_FALL', 'HA_TOT_PER']},\n",
    "                      \"PERSONAS\": {\"useful_columns\": ['U_DPTO', 'U_MPIO', 'UA_CLASE', 'U_EDIFICA',\n",
    "                                                      'COD_ENCUESTAS', 'U_VIVIENDA', 'P_NROHOG', 'P_NRO_PER', 'P_SEXO',\n",
    "                                                      'P_EDADR', 'P_PARENTESCOR', 'PA_LUG_NAC',\n",
    "                                                      'PA_VIVIA_5ANOS', 'PA_VIVIA_1ANO', 'P_ENFERMO', 'P_QUEHIZO_PPAL',\n",
    "                                                      'PA_LO_ATENDIERON', 'PA1_CALIDAD_SERV', 'CONDICION_FISICA',\n",
    "                                                      'P_ALFABETA', 'PA_ASISTENCIA', 'P_NIVEL_ANOSR', 'P_TRABAJO',\n",
    "                                                      'P_EST_CIVIL', 'PA_HNV', 'PA1_THNV', 'PA2_HNVH', 'PA3_HNVM', 'PA_HNVS',\n",
    "                                                      'PA1_THSV', 'PA2_HSVH', 'PA3_HSVM', 'PA_HFC', 'PA1_THFC', 'PA2_HFCH',\n",
    "                                                      'PA3_HFCM']},\n",
    "                      \"FALLECIDOS\": {\"useful_columns\": ['U_DPTO', 'U_MPIO', 'UA_CLASE', 'COD_ENCUESTAS',\n",
    "                                                        'U_VIVIENDA', 'F_NROHOG', 'FA1_NRO_FALL', 'FA2_SEXO_FALL',\n",
    "                                                        'FA3_EDAD_FALL', 'FA4_CERT_DEFUN']},\n",
    "                      \"GEOREFERENCIACION\": {\"useful_columns\": ['U_DPTO', 'U_MPIO', 'UA_CLASE', 'UA1_LOCALIDAD', 'U_SECT_RUR',\n",
    "                                                               'U_SECC_RUR', 'UA2_CPOB', 'U_SECT_URB', 'U_SECC_URB', 'U_MZA',\n",
    "                                                               'U_EDIFICA', 'COD_ENCUESTAS', 'U_VIVIENDA']},\n",
    "                      \"DIVIPOLA\": {\"useful_columns\": ['cod_depto', 'cod_mpio', 'dpto', 'nom_mpio', 'tipo_municipio']}\n",
    "                      },\n",
    "            }\n",
    "\n",
    "bucket='censo-covid'\n",
    "s3_resource = boto3.resource('s3')\n",
    "bucket_s3 = s3_resource.Bucket(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "censo_covid_bucket_s3 = f\"s3a://{bucket}\"\n",
    "\n",
    "raw_data_path = os.path.join(censo_covid_bucket_s3, \"raw-data\")\n",
    "censo_data_path = os.path.join(raw_data_path, \"censo\")\n",
    "covid_tests_path = os.path.join(raw_data_path, \"covid-tests.csv\")\n",
    "covid_path = os.path.join(raw_data_path, \"covid.csv\")\n",
    "divipola_path = os.path.join(raw_data_path, \"divipola.csv\")\n",
    "\n",
    "dict_paths_departments = get_censo_paths(bucket_s3, directory_key=os.path.join(\"raw-data\", \"censo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51968da9121e4d20be569a06fe923628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test\n",
    "if len(list(bucket_s3.objects.filter(Prefix=f\"{data_path}/engaging-users-test\", Delimiter='./')))==0:\n",
    "    df = parse_data(test_path, has_labels=False).repartition(200)\n",
    "    engaging_users_test = df.select(\"engaging_user_id\").distinct()\n",
    "    engaging_users_test.write.csv(engaging_users_test_path)\n",
    "\n",
    "engaging_users_test = spark.read.csv(engaging_users_test_path, \n",
    "                                    schema=StructType([StructField('engaging_user_id', StringType())]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_data = spark.read.csv(covid_path, \n",
    "                            schema=build_schema_covid(source=\"covid\"))\n",
    "covid_tests_data = spark.read.csv(covid_tests_path, \n",
    "                                  schema=build_schema_covid(source=\"tests\"))\n",
    "divipola_data = spark.read.csv(divipola_path, \n",
    "                                  schema=build_schema_divipola(source=\"divipola\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data_dict={}\n",
    "for department, val in dict_paths_departments.items():\n",
    "    for table, table_path in val.items():\n",
    "        if not(table in census_data_dict):\n",
    "            census_data_dict[table] = spark.read.csv(table_path, schema=build_schema_census(source=table))\n",
    "        else:\n",
    "            aux = spark.read.csv(table_path, schema=build_schema_census(source=table))\n",
    "            census_data_dict[table] = census_data_dict[table].union(aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_viv_cols = [col for col in census_data_dict[\"VIV\"].columns\\\n",
    "                 if col not in metadata[\"CENSO\"][\"VIVIENDA\"][\"useful_columns\"]]\n",
    "census_data_dict[\"VIV\"] = census_data_dict[\"VIV\"].drop(drop_viv_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_hog_cols = [col for col in census_data_dict[\"HOG\"].columns\\\n",
    "                 if col not in metadata[\"CENSO\"][\"HOGAR\"][\"useful_columns\"]]\n",
    "census_data_dict[\"HOG\"] = census_data_dict[\"HOG\"].drop(drop_hog_cols)\n",
    "census_data_dict[\"HOG\"] = census_data_dict[\"HOG\"].fillna(99, subset=['H_NROHOG'])\n",
    "census_data_dict[\"HOG\"] = census_data_dict[\"HOG\"].withColumn(\"H_NROHOG\", F.col(\"H_NROHOG\").cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_per_cols = [col for col in census_data_dict[\"PER\"].columns\\\n",
    "                 if col not in metadata[\"CENSO\"][\"PERSONAS\"][\"useful_columns\"]]\n",
    "census_data_dict[\"PER\"] = census_data_dict[\"PER\"].drop(drop_per_cols)\n",
    "census_data_dict[\"PER\"] = census_data_dict[\"PER\"].fillna(99, subset=['P_NROHOG'])\n",
    "census_data_dict[\"PER\"] = census_data_dict[\"PER\"].withColumn(\"P_NROHOG\", F.col(\"P_NROHOG\").cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_fall_cols = [col for col in census_data_dict[\"FALL\"].columns\\\n",
    "                 if col not in metadata[\"CENSO\"][\"FALLECIDOS\"][\"useful_columns\"]]\n",
    "census_data_dict[\"FALL\"] = census_data_dict[\"FALL\"].drop(drop_fall_cols)\n",
    "census_data_dict[\"FALL\"] = census_data_dict[\"FALL\"].fillna(99, subset=['F_NROHOG'])\n",
    "census_data_dict[\"FALL\"] = census_data_dict[\"FALL\"].withColumn(\"F_NROHOG\", F.col(\"F_NROHOG\").cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_mgn_cols = [col for col in census_data_dict[\"MGN\"].columns\\\n",
    "                 if col not in metadata[\"CENSO\"][\"GEOREFERENCIACION\"][\"useful_columns\"]]\n",
    "census_data_dict[\"MGN\"] = census_data_dict[\"MGN\"].drop(drop_mgn_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JoinTables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_complete = census_data_dict[\"PER\"].join(census_data_dict[\"VIV\"], \n",
    "                                               on=['U_DPTO', 'U_MPIO', 'UA_CLASE', \n",
    "                                                   'U_EDIFICA', 'COD_ENCUESTAS',\n",
    "                                                   'U_VIVIENDA'],\n",
    "                                               how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_per_complete.filter(F.col(\"UVA_USO_UNIDAD\").isNull()).count() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_complete = df_per_complete.merge(census_data_dict[\"HOG\"], \n",
    "                                        how=\"left\", \n",
    "                                        left_on=['U_DPTO', 'U_MPIO', 'UA_CLASE', 'COD_ENCUESTAS', 'U_VIVIENDA', 'P_NROHOG'], \n",
    "          right_on=['U_DPTO', 'U_MPIO', 'UA_CLASE', 'COD_ENCUESTAS', 'U_VIVIENDA', 'H_NROHOG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2124a2196218409c9cdf1db7638b21b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test"
     ]
    }
   ],
   "source": [
    "if submission:\n",
    "    print(\"Submission\")\n",
    "elif test:\n",
    "    print(\"Test\")\n",
    "else:\n",
    "    if training:\n",
    "        print(\"Train\")\n",
    "        df = train\n",
    "    else:\n",
    "        print(\"Validation\")\n",
    "        df = val    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8840e7a24e41aeae1279f3ec5be75e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12434838"
     ]
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad173690fc20425d98abe262e22148b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hashtags': 9802258, 'present_media': 7855555, 'present_links': 10560235, 'present_domains': 10560235}"
     ]
    }
   ],
   "source": [
    "columns_w_nan = validator(df)\n",
    "print(columns_w_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac46ee7dd23e4f48ab8de604f42d0459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not(submission) and not(test):\n",
    "    df = df.withColumn('indicator_reply',F.when(F.col('reply_timestamp').isNotNull(), 1).otherwise(0))\n",
    "    df = df.withColumn('indicator_retweet',F.when(F.col('retweet_timestamp').isNotNull(), 1).otherwise(0))\n",
    "    df = df.withColumn('indicator_retweet_with_comment',\n",
    "                       F.when(F.col('retweet_with_comment_timestamp').isNotNull(),1).otherwise(0))\n",
    "    df = df.withColumn('indicator_like', F.when(F.col('like_timestamp').isNotNull(),1).otherwise(0))\n",
    "    df = df.withColumn('indicator_interaction', \n",
    "                       F.when(F.col('indicator_reply')+\\\n",
    "                              F.col('indicator_retweet')+\\\n",
    "                              F.col('indicator_retweet_with_comment')+\\\n",
    "                              F.col('indicator_like')>0, 1)\\\n",
    "                       .otherwise(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intention_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0adb881de994db2ace45a20a2b85777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if training:\n",
    "    if len(list(bucket_s3.objects.filter(Prefix=f\"{data_path}/intentions-\"+suffix_sample, Delimiter='./')))==0:\n",
    "        print(\"Creating Intention\")\n",
    "        intention_df = df.select(\"engaging_user_id\", \"indicator_reply\", \"indicator_retweet\", \n",
    "                                    \"indicator_retweet_with_comment\", \"indicator_like\", \"indicator_interaction\")\\\n",
    "                        .groupBy(\"engaging_user_id\").agg(F.sum(F.col(\"indicator_interaction\")).alias(\"n_interactions\"), \n",
    "                                                         F.sum(F.col(\"indicator_retweet_with_comment\"))\\\n",
    "                                                         .alias(\"n_commented\"),\n",
    "                                                         F.sum(F.col(\"indicator_like\")).alias(\"n_liked\"),\n",
    "                                                         F.sum(F.col(\"indicator_reply\")).alias(\"n_replied\"),\n",
    "                                                         F.sum(F.col(\"indicator_retweet\")).alias(\"n_retweeted\"),\n",
    "                                                         F.count(F.col(\"indicator_interaction\"))\\\n",
    "                                                         .alias(\"total_appearance\"))\n",
    "        columns = ['n_interactions', 'n_commented', 'n_liked', 'n_replied', 'n_retweeted']\n",
    "        for col_i in columns:\n",
    "            intention_df = intention_df.withColumn(\"perc_\" + col_i, F.col(col_i)/(F.col(\"total_appearance\")))\n",
    "        intention_df = intention_df.drop(*columns)\n",
    "        join_users_not_test = join_users_not_test.select(F.col(\"engaging_user_id\").alias(\"drop_users\"))\n",
    "        join_users_not_test = join_users_not_test.sample(withReplacement=False,\n",
    "                                                         fraction=0.15,\n",
    "                                                         seed=42)\n",
    "        intention_df = intention_df.join(join_users_not_test, \n",
    "                                         intention_df.engaging_user_id==join_users_not_test.drop_users, \n",
    "                                         how=\"left_anti\").drop(\"drop_users\")\n",
    "        intention_df.repartition(1000).write.csv(intentions_path)\n",
    "    else:\n",
    "        print(\"Intention already created\")\n",
    "schema = StructType([StructField('engaging_user_id', StringType()),\n",
    "             StructField('total_appearance', LongType()),\n",
    "             StructField('perc_n_interactions', DoubleType()),\n",
    "             StructField('perc_n_commented', DoubleType()),\n",
    "             StructField('perc_n_liked', DoubleType()),\n",
    "             StructField('perc_n_replied', DoubleType()),\n",
    "             StructField('perc_n_retweeted', DoubleType())])\n",
    "intention_df = spark.read.csv(intentions_path, schema=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5369efd8a0c842b7b48ab664680c1298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if training:\n",
    "    print(\"Creating hashtags features\")\n",
    "    mapping_hashtag_encode, mapping_hashtag_count = mappings(df, \"hashtags\", top_k_hashtags)\n",
    "    # Saving pkl\n",
    "    save_pkl_to_s3(mapping_hashtag_encode, key_hashtag_mapping, bucket)\n",
    "    save_pkl_to_s3(mapping_hashtag_count, key_hashtag_count, bucket)\n",
    "\n",
    "# Load dict mapping language\n",
    "mapping_hashtag_encode = pickle.loads(s3_resource.Bucket(bucket).Object(key_hashtag_mapping).get()['Body'].read())\n",
    "mapping_hashtag_count = pickle.loads(s3_resource.Bucket(bucket).Object(key_hashtag_count).get()['Body'].read())\n",
    "        \n",
    "hashtagsEncoder_udf = F.udf(lambda x: labelEncoder(x, mapping_hashtag_encode), \n",
    "                         StringType())\n",
    "df = df.withColumn('hashtagEncoded', hashtagsEncoder_udf(df.hashtags))\n",
    "hashtagSumCounter_udf = F.udf(lambda x: hashtagSumCounter(x, mapping_hashtag_count), \n",
    "                             IntegerType())\n",
    "df = df.withColumn('hashtagSumCount', hashtagSumCounter_udf(df['hashtags']))\n",
    "df = df.withColumn('hashtagCount', listCounter_udf(df.hashtags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6a285e79a64a2ba3e75816d1359c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if training:\n",
    "    print(\"Creating domains features\")\n",
    "    mapping_domain_encode, mapping_domain_count = mappings(df, \"present_domains\", top_k_domains)\n",
    "    # Saving pkl\n",
    "    save_pkl_to_s3(mapping_domain_encode, key_domain_mapping, bucket)\n",
    "    save_pkl_to_s3(mapping_domain_count, key_domain_count, bucket)\n",
    "\n",
    "# Load dict mapping language\n",
    "mapping_domain_encode = pickle.loads(s3_resource.Bucket(bucket).Object(key_domain_mapping).get()['Body'].read())\n",
    "\n",
    "domainEncoder_udf = F.udf(lambda x: labelEncoder(x, mapping_domain_encode), \n",
    "                         StringType())\n",
    "df = df.withColumn('domainEncoded', domainEncoder_udf(df.present_domains))\n",
    "df = df.withColumn('domainCount', listCounter_udf(df.present_domains))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "143a9fa2cad843169569e418c8b284f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if training:\n",
    "    print(\"Creating language features\")\n",
    "    mapping_encoder = mapping_label_encoder(df, \"language\", top_k_languages)\n",
    "    save_pkl_to_s3(mapping_encoder, key_language_mapping, bucket)\n",
    "\n",
    "# Load dict mapping language\n",
    "mapping_language_encode = pickle.loads(s3_resource.Bucket(bucket).Object(key_language_mapping).get()['Body'].read())\n",
    "        \n",
    "languageEncoder_udf = F.udf(lambda x: labelEncoderSingle(x, mapping_language_encode)[0], \n",
    "                         StringType())\n",
    "df = df.withColumn('languageEncoded', languageEncoder_udf(df.language))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b663aa1e7cd4515bc43e8c080a9f5b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dict_media_counter={'PhotoCount': PhotoCounter_udf,\n",
    "                    'VideoCount': VideoCounter_udf, \n",
    "                    'GIFCount': GifCounter_udf}\n",
    "for media, media_fun in dict_media_counter.items():\n",
    "    df = df.withColumn(media, media_fun(df.present_media))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dfda37082e5406e981e84522dd60e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.withColumn('linkCount', listCounter_udf(df.present_links))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweet_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6aaed1137df4df2b6b630ac53886218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.withColumn('tweetEncoded', tweet_encoded_udf(df.tweet_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timestamp_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9acfb520708947b4b7c9d6a66f9bf1c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "timestamp_feats = [i for i in df.columns if (('timestamp' in i) or ('creation' in i))]\n",
    "\n",
    "# Timestamp to dates\n",
    "for col_ts in timestamp_feats:\n",
    "    # Taking only the preffix of each column\n",
    "    preffix = col_ts.split(\"_timestamp\")[0]\n",
    "    df = df.withColumn(preffix + \"_date\", F.from_unixtime(col_ts, 'yyyy-MM-dd HH:mm:ss'))\n",
    "\n",
    "# From tweet_date extracting day of week, week of month and hour of tweet\n",
    "df = df.withColumn( 'tweet_timestamp_day_of_week', F.date_format(F.col('tweet_date'), 'u') )\n",
    "df = df.withColumn( 'tweet_timestamp_week_of_month',  F.date_format(F.col('tweet_date'), \"W\" ) )\n",
    "df = df.withColumn( 'tweet_timestamp_hour',  F.date_format(F.col('tweet_date'), \"H\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling_features\n",
    "As standard scaling will be done manually, we have to create some dictionaries to save the information of the scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf3107d2964c4abead6e8beaea315a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if training: \n",
    "    scaling_dict = dict()\n",
    "else:\n",
    "    scaling_dict = pickle.loads(s3_resource.Bucket(bucket).Object(key_scaling_features).get()['Body'].read())\n",
    "    assert type(scaling_dict) == dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329b47bf600a475c89dde6ebd5ec2de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Seconds from engagee account creation to tweet posting\n",
    "# Differences of timestamps return a result inv Seconds\n",
    "df = df.withColumn( 'tweet_timestamp_to_engagee_account_creation',  \n",
    "                   F.col('tweet_timestamp') - F.col('engaged_with_user_account_creation'))\n",
    "if training: \n",
    "    mean_col, sttdev_col = df.select(F.mean('tweet_timestamp_to_engagee_account_creation'),\n",
    "                                     F.stddev('tweet_timestamp_to_engagee_account_creation')).first()\n",
    "    # Saving scaling features\n",
    "    scaling_dict['tweet_timestamp_to_engagee_account_creation'] = { 'mean': mean_col, 'std': sttdev_col}    \n",
    "mean_col = scaling_dict['tweet_timestamp_to_engagee_account_creation']['mean']    \n",
    "sttdev_col = scaling_dict['tweet_timestamp_to_engagee_account_creation']['std']\n",
    "    \n",
    "df = df.withColumn('tweet_timestamp_to_engagee_account_creation'+'_ss', \n",
    "                   (F.col('tweet_timestamp_to_engagee_account_creation') - mean_col) / (2*sttdev_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e67b2d70a9d74f82bc0616e1fc3306aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Seconds from engaging account creation to tweet posting\n",
    "# Differences of timestamps return a result inv Seconds\n",
    "df = df.withColumn( 'tweet_timestamp_to_engaging_account_creation',  \n",
    "                   F.col('tweet_timestamp') - F.col('engaging_user_account_creation'))\n",
    "#Scaling\n",
    "if training: \n",
    "    mean_col, sttdev_col = df.select(F.mean('tweet_timestamp_to_engaging_account_creation'), \n",
    "                                     F.stddev('tweet_timestamp_to_engaging_account_creation')).first()\n",
    "    # Saving scaling features\n",
    "    scaling_dict['tweet_timestamp_to_engaging_account_creation'] = { 'mean': mean_col, 'std': sttdev_col}    \n",
    "mean_col = scaling_dict['tweet_timestamp_to_engaging_account_creation']['mean']    \n",
    "sttdev_col = scaling_dict['tweet_timestamp_to_engaging_account_creation']['std']\n",
    "\n",
    "df = df.withColumn('tweet_timestamp_to_engaging_account_creation'+'_ss', \n",
    "                   (F.col('tweet_timestamp_to_engaging_account_creation') - mean_col) / (2*sttdev_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Followers_and_Followings_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59bb3bede402458297ddd6f1871662fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.withColumn('engaged_with_vs_engaging_follower_diff',\n",
    "                   F.col('engaged_with_user_follower_count') - F.col('engaging_user_follower_count'))\n",
    "df = df.withColumn('engaged_with_vs_engaging_following_diff', \n",
    "                   F.col('engaged_with_user_following_count') - F.col('engaging_user_following_count'))\n",
    "df = df.withColumn('engaged_follow_diff',\n",
    "                   F.col('engaged_with_user_follower_count') - F.col('engaged_with_user_following_count'))\n",
    "df = df.withColumn('engaging_follow_diff', \n",
    "                   F.col('engaging_user_follower_count') - F.col('engaging_user_following_count'))\n",
    "df = df.withColumn('engaged_follower_diff_engaging_following', \n",
    "                   F.col('engaged_with_user_follower_count') - F.col('engaging_user_following_count'))\n",
    "df = df.withColumn('engaged_following_diff_engaging_follower', \n",
    "                   F.col('engaged_with_user_following_count') - F.col('engaging_user_follower_count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5374fa232f3423c80850b7c5a33edd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = [\"engaged_with_vs_engaging_follower_diff\", \"engaged_with_vs_engaging_following_diff\", \n",
    "           \"engaged_follow_diff\", \"engaging_follow_diff\", \"engaged_follower_diff_engaging_following\", \n",
    "           \"engaged_following_diff_engaging_follower\"]\n",
    "if training:\n",
    "    diff_min_dict = {}\n",
    "    for col in columns:\n",
    "        diff_min_dict[col] = df.select(F.min(col)).first()[0]\n",
    "    save_pkl_to_s3(diff_min_dict, key_diff_min, bucket)\n",
    "        \n",
    "diff_min_dict = pickle.loads(s3_resource.Bucket(bucket).Object(key_diff_min).get()['Body'].read())\n",
    "for col in columns:\n",
    "    df = df.withColumn(col, F.col(col)-diff_min_dict[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log and Standard Scaling of followers and difference features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8588a162273c4ee38adc9c2e7b2ddbb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Followers/following counts and differences will transformed to logarithm. We are choosing the column names.\n",
    "columns_to_log = ['engaged_with_vs_engaging_follower_diff', 'engaged_with_vs_engaging_following_diff', \n",
    "                    'engaged_follow_diff', 'engaging_follow_diff', \n",
    "                    'engaged_follower_diff_engaging_following', 'engaged_following_diff_engaging_follower', \n",
    "                    'engaged_with_user_follower_count', 'engaging_user_follower_count', \n",
    "                    'engaged_with_user_following_count', 'engaging_user_following_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a624736ac68443284c5e38162637eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for column in columns_to_log:\n",
    "    df = df.withColumn(column + '_log', F.log(F.col(column)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6740a511108d4df084898722dab567c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols_to_scale = [column for column in df.columns if ('_log' in column)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b02deee6bd644e40951a5e54054e040d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if training:\n",
    "    for col in cols_to_scale:\n",
    "        mean_col, sttdev_col = df.select(F.mean(col), F.stddev(col)).first()\n",
    "        scaling_dict[col] = { 'mean': mean_col, 'std': sttdev_col}\n",
    "\n",
    "for col in cols_to_scale:\n",
    "    mean_col = scaling_dict[col]['mean']\n",
    "    sttdev_col = scaling_dict[col]['std']\n",
    "    df = df.withColumn(col+'_ss', (F.col(col) - mean_col) / (2*sttdev_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantile_Discretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70bdaea1ea544aab9ead4351b63d65be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if training:\n",
    "    qds_obj = {}\n",
    "    qds_paths\n",
    "    for col in qds_paths.keys():\n",
    "        qds = QuantileDiscretizer(numBuckets=50, inputCol=col, outputCol=col+\"_q\")\n",
    "        qds = qds.fit(df)\n",
    "        qds.save(qds_paths[col])\n",
    "        \n",
    "for col in qds_paths.keys():\n",
    "    qds = QuantileDiscretizer.load(qds_paths[col])\n",
    "    df = qds.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intentions_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d986237c931c4b40b8f78b768458f620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.join(intention_df, \n",
    "             on=\"engaging_user_id\", \n",
    "             how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96dd72435faf4892afea67ed982c8ea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = [\"perc_n_interactions\", 'perc_n_commented', 'perc_n_liked', 'perc_n_replied', 'perc_n_retweeted']\n",
    "if training:\n",
    "    dict_mean_perc = {}\n",
    "    for col in columns:\n",
    "        dict_mean_perc[col] = intention_df.select(F.mean(col)).first()[0]\n",
    "    save_pkl_to_s3(dict_mean_perc, key_impute_perc, bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa256e00c5f94c8ea1a4125fcaec6fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_cols_to_scale = [\"hashtagSumCount\", \"hashtagCount\",\n",
    "                     \"domainCount\", \"PhotoCount\",\n",
    "                     \"VideoCount\", \"GIFCount\",\n",
    "                     \"linkCount\", \"total_appearance\",\n",
    "                     \"perc_n_interactions\",\n",
    "                     \"perc_n_commented\",\n",
    "                     \"perc_n_liked\",\n",
    "                     \"perc_n_replied\",\n",
    "                     \"perc_n_retweeted\"]\n",
    "#Scaling\n",
    "if training:\n",
    "    for col in num_cols_to_scale:\n",
    "        mean_col, sttdev_col = df.select(F.mean(col), F.stddev(col)).first()\n",
    "        scaling_dict[col] = {'mean': mean_col, 'std': sttdev_col}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DiffsImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac6dbfbd37c43a2ae83399211f28187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = ['engaged_with_vs_engaging_follower_diff_log_ss', \n",
    "           'engaged_with_vs_engaging_following_diff_log_ss', \n",
    "           'engaged_follow_diff_log_ss', \n",
    "           'engaging_follow_diff_log_ss', \n",
    "           'engaged_follower_diff_engaging_following_log_ss', \n",
    "           'engaged_following_diff_engaging_follower_log_ss']\n",
    "for col in columns:\n",
    "    df = df.withColumn(col, F.when(F.col(col).isNotNull(), F.col(col)).otherwise(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IntentionsImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2606ec1c3b404f5189e8f3ccdefd95d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.withColumn('total_appearance', F.when(F.col(\"total_appearance\").isNotNull(), \n",
    "                                                   F.col(\"total_appearance\"))\\\n",
    "                          .otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a93ecf829b54deba41b7de9563a4f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = [\"perc_n_interactions\", 'perc_n_commented', 'perc_n_liked', 'perc_n_replied', 'perc_n_retweeted']\n",
    "        \n",
    "dict_mean_perc = pickle.loads(s3_resource.Bucket(bucket).Object(key_impute_perc).get()['Body'].read())\n",
    "for col in columns:\n",
    "    df = df.withColumn(col, F.when(F.col(col).isNotNull(), F.col(col))\\\n",
    "                       .otherwise(dict_mean_perc[col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling after imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fadd90e4bd134758b9db04332f7f9069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for col in num_cols_to_scale:\n",
    "    mean_col = scaling_dict[col]['mean']\n",
    "    sttdev_col = scaling_dict[col]['std']\n",
    "    df = df.withColumn(col+'_ss', (F.col(col) - mean_col) / (2*sttdev_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eef42af51a5437abf368d81399f191a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deviations_to_clip = 5.0\n",
    "for col in num_cols_to_scale:\n",
    "    df = df.withColumn(col+'_ss', F.when(F.abs(F.col(col+'_ss'))<5, \n",
    "                                         F.col(col+'_ss'))\\\n",
    "                       .otherwise(deviations_to_clip))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving scaling_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7356cf5d2544c2197e655dcde488a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if training: \n",
    "    # Saving scaling dictionary to pickle\n",
    "    save_pkl_to_s3(scaling_dict, key_scaling_features, bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FeatureSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bb6556f96a745f0a9d69a294d0f9ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original = ['text_tokens', 'tweet_id', 'engaged_with_user_id', 'engaged_with_user_is_verified',\n",
    "            'engaging_user_id', 'engaging_user_is_verified', 'engagee_follows_engager']\n",
    "\n",
    "processed = ['hashtagEncoded', 'hashtagSumCount_ss', 'hashtagCount_ss', #hashtags\n",
    "             'domainEncoded', 'domainCount_ss', #domains\n",
    "             'tweetEncoded', # tweet type encoded\n",
    "             'languageEncoded',# language encoded\n",
    "             'tweet_timestamp_day_of_week', 'tweet_timestamp_week_of_month', 'tweet_timestamp_hour', #tweet timestamp\n",
    "             'tweet_timestamp_to_engagee_account_creation_ss', #engagee time in twitter proxy\n",
    "             'tweet_timestamp_to_engaging_account_creation_ss', #engaging time in twitter proxy\n",
    "             'engaged_with_vs_engaging_follower_diff_log_ss', #followers engaged\n",
    "             'engaged_with_vs_engaging_following_diff_log_ss', #followings engaged\n",
    "             'engaged_follow_diff_log_ss', #diff follows engaged\n",
    "             'engaging_follow_diff_log_ss', #diff follows engaging\n",
    "             'engaged_follower_diff_engaging_following_log_ss',  #followings engaging\n",
    "             'engaged_following_diff_engaging_follower_log_ss', #followers engaging\n",
    "             'engaged_with_user_follower_count_log_ss', #engaged follower count\n",
    "             'engaging_user_follower_count_log_ss', #engaging follower count\n",
    "             'engaged_with_user_following_count_log_ss',  #engaged following count\n",
    "             'engaging_user_following_count_log_ss', #engaging following count\n",
    "             'PhotoCount_ss', 'VideoCount_ss', 'GIFCount_ss', 'linkCount_ss', #media\n",
    "             'engaged_with_user_follower_count_q', 'engaged_with_user_following_count_q', #Quantile\n",
    "             'engaged_with_user_account_creation_q', 'engaging_user_follower_count_q', #Quantile\n",
    "             'engaging_user_following_count_q', 'engaging_user_account_creation_q', #Quantile\n",
    "             'total_appearance_ss', 'perc_n_interactions_ss', 'perc_n_commented_ss', \n",
    "             'perc_n_liked_ss', 'perc_n_replied_ss', 'perc_n_retweeted_ss' #intentions\n",
    "             ]\n",
    "\n",
    "labels = ['indicator_reply', 'indicator_retweet', 'indicator_retweet_with_comment',\n",
    "          'indicator_like', 'indicator_interaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd7dcb7430046f2a2c6e2bf1732a1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if submission:\n",
    "    cols_to_select = original + processed\n",
    "elif test:\n",
    "    cols_to_select = original + processed\n",
    "else:\n",
    "    cols_to_select = original + processed + labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5902dbe8be7740f0a1e70fe7f918cce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_df = df.select(cols_to_select)\n",
    "columns = columns2cast(new_df)\n",
    "new_df = cast_array2string(new_df, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5427e7ad40ba4a10a2d6e25028a3f6b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dict_types = {'bool': ['engaged_with_user_is_verified', 'engaging_user_is_verified', 'engagee_follows_engager'],\n",
    "              'id': ['tweet_id', 'engaged_with_user_id', 'engaging_user_id'], \n",
    "              'num': ['hashtagSumCount_ss', 'hashtagCount_ss', \n",
    "                      'domainCount_ss', \n",
    "                      'tweet_timestamp_to_engagee_account_creation_ss', #engagee time in twitter proxy\n",
    "                      'tweet_timestamp_to_engaging_account_creation_ss', #engaging time in twitter proxy\n",
    "                      'engaged_with_vs_engaging_follower_diff_log_ss', #followers engaged\n",
    "                      'engaged_with_vs_engaging_following_diff_log_ss', #followings engaged\n",
    "                      'engaged_follow_diff_log_ss', #diff follows engaged\n",
    "                      'engaging_follow_diff_log_ss', #diff follows engaging\n",
    "                      'engaged_follower_diff_engaging_following_log_ss',  #followings engaging\n",
    "                      'engaged_following_diff_engaging_follower_log_ss', #followers engaging\n",
    "                      'engaged_with_user_follower_count_log_ss', #engaged follower count\n",
    "                      'engaging_user_follower_count_log_ss', #engaging follower count\n",
    "                      'engaged_with_user_following_count_log_ss',  #engaged following count\n",
    "                      'engaging_user_following_count_log_ss', #engaging following count\n",
    "                      'PhotoCount_ss', 'VideoCount_ss', 'GIFCount_ss', 'linkCount_ss', #media\n",
    "                      'total_appearance_ss', 'perc_n_interactions_ss', 'perc_n_commented_ss', \n",
    "                      'perc_n_liked_ss', 'perc_n_replied_ss', 'perc_n_retweeted_ss' #intentions\n",
    "                     ], \n",
    "              'cat': ['tweetEncoded', 'languageEncoded',\n",
    "                      'tweet_timestamp_day_of_week', 'tweet_timestamp_week_of_month', 'tweet_timestamp_hour',\n",
    "                      'engaged_with_user_follower_count_q', 'engaged_with_user_following_count_q', #Quantile\n",
    "                      'engaged_with_user_account_creation_q', 'engaging_user_follower_count_q', #Quantile\n",
    "                      'engaging_user_following_count_q', 'engaging_user_account_creation_q', #Quantile\n",
    "                     ], \n",
    "              'ors': ['text_tokens'], \n",
    "              'unors':['hashtagEncoded', 'domainEncoded']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c878b80b3a9842cdbc094ebbf5a856dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key, val in dict_types.items():\n",
    "    for column in val:\n",
    "        new_df = new_df.withColumnRenamed(column, column + '_' + key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf939b5c1134ccc90ef71bff3aef0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12434838"
     ]
    }
   ],
   "source": [
    "new_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d19f9b709c4b00b89ac224b8812761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------+-----------------------+-----------------------+\n",
      "|summary|hashtagSumCount_ss_num|perc_n_retweeted_ss_num|total_appearance_ss_num|\n",
      "+-------+----------------------+-----------------------+-----------------------+\n",
      "|   mean|  -0.03561698913424515|   -0.02871487470125...|   -0.13855573076697658|\n",
      "|    50%|  -0.08201654219284023|   -0.07379754563317474|    -0.2589475275080297|\n",
      "|    min|  -0.08201654219284023|   -0.31412261503645766|    -0.4152207742939386|\n",
      "|    max|                   5.0|     1.6672083509634679|                    5.0|\n",
      "+-------+----------------------+-----------------------+-----------------------+"
     ]
    }
   ],
   "source": [
    "#stats = [\"mean\", \"50%\", \"min\", \"max\"]\n",
    "#new_df.select(\"hashtagSumCount_ss_num\", \n",
    "#              \"perc_n_retweeted_ss_num\", \n",
    "#              \"total_appearance_ss_num\").summary(*stats).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MergeUserBucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c31ae19460b4bb485ff4438e529ffe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "map_user_bucket = spark.read.csv(map_user_bucket_path, schema= StructType([StructField('user_id', StringType()),\n",
    "                                                                           StructField('final_bucket', IntegerType())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920b087ca2cf4a2abc2c7574e2a1faa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_df = new_df.join(map_user_bucket, new_df.engaged_with_user_id_id==map_user_bucket.user_id, how=\"left\")\n",
    "new_df = new_df.drop(\"user_id\")\n",
    "new_df = new_df.withColumnRenamed(\"final_bucket\", \"engaged_with_user_id_bucket\")\n",
    "\n",
    "new_df = new_df.join(map_user_bucket, new_df.engaging_user_id_id==map_user_bucket.user_id, how=\"left\")\n",
    "new_df = new_df.drop(\"user_id\")\n",
    "new_df = new_df.withColumnRenamed(\"final_bucket\", \"engaging_user_id_bucket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2e889e86f44eb489086ca1d3e5b587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[text_tokens_ors: string, tweet_id_id: string, engaged_with_user_id_id: string, engaged_with_user_is_verified_bool: boolean, engaging_user_id_id: string, engaging_user_is_verified_bool: boolean, engagee_follows_engager_bool: boolean, hashtagEncoded_unors: string, hashtagSumCount_ss_num: double, hashtagCount_ss_num: double, domainEncoded_unors: string, domainCount_ss_num: double, tweetEncoded_cat: int, languageEncoded_cat: string, tweet_timestamp_day_of_week_cat: string, tweet_timestamp_week_of_month_cat: string, tweet_timestamp_hour_cat: string, tweet_timestamp_to_engagee_account_creation_ss_num: double, tweet_timestamp_to_engaging_account_creation_ss_num: double, engaged_with_vs_engaging_follower_diff_log_ss_num: double, engaged_with_vs_engaging_following_diff_log_ss_num: double, engaged_follow_diff_log_ss_num: double, engaging_follow_diff_log_ss_num: double, engaged_follower_diff_engaging_following_log_ss_num: double, engaged_following_diff_engaging_follower_log_ss_num: double, engaged_with_user_follower_count_log_ss_num: double, engaging_user_follower_count_log_ss_num: double, engaged_with_user_following_count_log_ss_num: double, engaging_user_following_count_log_ss_num: double, PhotoCount_ss_num: double, VideoCount_ss_num: double, GIFCount_ss_num: double, linkCount_ss_num: double, engaged_with_user_follower_count_q_cat: double, engaged_with_user_following_count_q_cat: double, engaged_with_user_account_creation_q_cat: double, engaging_user_follower_count_q_cat: double, engaging_user_following_count_q_cat: double, engaging_user_account_creation_q_cat: double, total_appearance_ss_num: double, perc_n_interactions_ss_num: double, perc_n_commented_ss_num: double, perc_n_liked_ss_num: double, perc_n_replied_ss_num: double, perc_n_retweeted_ss_num: double, engaged_with_user_id_bucket: int, engaging_user_id_bucket: int]"
     ]
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8d6d3b7e664b6e9c3cec5fd273b86e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}"
     ]
    }
   ],
   "source": [
    "columns_w_nan = validator(new_df)\n",
    "print(columns_w_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb66e5b07c674f14aaec0dffdfb0a645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3a://twitter-challenge-factored/final-data/processed/submission-final-complete\n",
      "s3a://twitter-challenge-factored/final-data/processed/test-final-complete\n",
      "s3a://twitter-challenge-factored/final-data/processed/train-final-complete\n",
      "s3a://twitter-challenge-factored/final-data/processed/val-final-complete"
     ]
    }
   ],
   "source": [
    "print(processed_submission_path)\n",
    "print(processed_test_path)\n",
    "print(processed_train_path)\n",
    "print(processed_val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ed291223d534733957054d38db9c907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_submission_path = f\"hdfs:///submission-{suffix_sample}\"\n",
    "processed_test_path = f\"hdfs:///test-{suffix_sample}\"\n",
    "processed_train_path = f\"hdfs:///train-{suffix_sample}\"\n",
    "processed_val_path = f\"hdfs:///val-{suffix_sample}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bac04aa1fbd4dc69561cae5f03688b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test saved"
     ]
    }
   ],
   "source": [
    "if submission:\n",
    "    new_df.write.option(\"header\",\"true\").csv(processed_submission_path)\n",
    "    print(\"Submission saved\")\n",
    "elif test:\n",
    "    new_df.write.option(\"header\",\"true\").csv(processed_test_path)\n",
    "    print(\"Test saved\")\n",
    "elif training:\n",
    "    new_df.write.option(\"header\",\"true\").csv(processed_train_path)\n",
    "    print(\"Train saved\")\n",
    "else:\n",
    "    new_df.write.option(\"header\",\"true\").csv(processed_val_path)\n",
    "    print(\"Valid saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REPLACE FOR S3-DIST-CP\n",
    "s3-dist-cp --src hdfs:///test-final-complete --dest s3://twitter-challenge-factored/final-data/processed/test-final-complete\n",
    "s3-dist-cp --src hdfs:///test-final-complete --dest s3://twitter-challenge-factored/final-data/processed/test-final-complete\n",
    "s3-dist-cp --src hdfs:///test-final-complete --dest s3://twitter-challenge-factored/final-data/processed/test-final-complete\n",
    "s3-dist-cp --src hdfs:///test-final-complete --dest s3://twitter-challenge-factored/final-data/processed/test-final-complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069b13c354ee4e0bbb4109403f895669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(List(StructField(text_tokens_ors,StringType,true),StructField(tweet_id_id,StringType,true),StructField(engaged_with_user_id_id,StringType,true),StructField(engaged_with_user_is_verified_bool,BooleanType,true),StructField(engaging_user_id_id,StringType,true),StructField(engaging_user_is_verified_bool,BooleanType,true),StructField(engagee_follows_engager_bool,BooleanType,true),StructField(hashtagEncoded_unors,StringType,true),StructField(hashtagSumCount_ss_num,DoubleType,true),StructField(hashtagCount_ss_num,DoubleType,true),StructField(domainEncoded_unors,StringType,true),StructField(domainCount_ss_num,DoubleType,true),StructField(tweetEncoded_cat,IntegerType,true),StructField(languageEncoded_cat,StringType,true),StructField(tweet_timestamp_day_of_week_cat,StringType,true),StructField(tweet_timestamp_week_of_month_cat,StringType,true),StructField(tweet_timestamp_hour_cat,StringType,true),StructField(tweet_timestamp_to_engagee_account_creation_ss_num,DoubleType,true),StructField(tweet_timestamp_to_engaging_account_creation_ss_num,DoubleType,true),StructField(engaged_with_vs_engaging_follower_diff_log_ss_num,DoubleType,true),StructField(engaged_with_vs_engaging_following_diff_log_ss_num,DoubleType,true),StructField(engaged_follow_diff_log_ss_num,DoubleType,true),StructField(engaging_follow_diff_log_ss_num,DoubleType,true),StructField(engaged_follower_diff_engaging_following_log_ss_num,DoubleType,true),StructField(engaged_following_diff_engaging_follower_log_ss_num,DoubleType,true),StructField(engaged_with_user_follower_count_log_ss_num,DoubleType,true),StructField(engaging_user_follower_count_log_ss_num,DoubleType,true),StructField(engaged_with_user_following_count_log_ss_num,DoubleType,true),StructField(engaging_user_following_count_log_ss_num,DoubleType,true),StructField(PhotoCount_ss_num,DoubleType,true),StructField(VideoCount_ss_num,DoubleType,true),StructField(GIFCount_ss_num,DoubleType,true),StructField(linkCount_ss_num,DoubleType,true),StructField(engaged_with_user_follower_count_q_cat,DoubleType,true),StructField(engaged_with_user_following_count_q_cat,DoubleType,true),StructField(engaged_with_user_account_creation_q_cat,DoubleType,true),StructField(engaging_user_follower_count_q_cat,DoubleType,true),StructField(engaging_user_following_count_q_cat,DoubleType,true),StructField(engaging_user_account_creation_q_cat,DoubleType,true),StructField(total_appearance_ss_num,DoubleType,true),StructField(perc_n_interactions_ss_num,DoubleType,true),StructField(perc_n_commented_ss_num,DoubleType,true),StructField(perc_n_liked_ss_num,DoubleType,true),StructField(perc_n_replied_ss_num,DoubleType,true),StructField(perc_n_retweeted_ss_num,DoubleType,true),StructField(indicator_reply,IntegerType,false),StructField(indicator_retweet,IntegerType,false),StructField(indicator_retweet_with_comment,IntegerType,false),StructField(indicator_like,IntegerType,false),StructField(indicator_interaction,IntegerType,false),StructField(engaged_with_user_id_bucket,IntegerType,true),StructField(engaging_user_id_bucket,IntegerType,true)))"
     ]
    }
   ],
   "source": [
    "new_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StructType([StructField(\"text_tokens_ors\",StringType),\n",
    "            StructField(\"tweet_id_id\",StringType),\n",
    "            StructField(\"engaged_with_user_id_id\",StringType),\n",
    "            StructField(\"engaged_with_user_is_verified_bool\",BooleanType),\n",
    "            StructField(\"engaging_user_id_id\",StringType),\n",
    "            StructField(\"engaging_user_is_verified_bool\",BooleanType),\n",
    "            StructField(\"engagee_follows_engager_bool\",BooleanType),\n",
    "            StructField(\"hashtagEncoded_unors\",StringType),\n",
    "            StructField(\"hashtagSumCount_num\",IntegerType),\n",
    "            StructField(\"hashtagCount_num\",IntegerType),\n",
    "            StructField(\"domainEncoded_unors\",StringType),\n",
    "            StructField(\"domainCount_num\",IntegerType),\n",
    "            StructField(\"tweetEncoded_cat\",IntegerType),\n",
    "            StructField(\"languageEncoded_cat\",StringType),\n",
    "            StructField(\"tweet_timestamp_day_of_week_cat\",StringType),\n",
    "            StructField(\"tweet_timestamp_week_of_month_cat\",StringType),\n",
    "            StructField(\"tweet_timestamp_hour_cat\",StringType),\n",
    "            StructField(\"tweet_timestamp_to_engagee_account_creation_ss_num\",DoubleType),\n",
    "            StructField(\"tweet_timestamp_to_engaging_account_creation_ss_num\",DoubleType),\n",
    "            StructField(\"engaged_with_vs_engaging_follower_diff_log_ss_num\",DoubleType),\n",
    "            StructField(\"engaged_with_vs_engaging_following_diff_log_ss_num\",DoubleType),\n",
    "            StructField(\"engaged_follow_diff_log_ss_num\",DoubleType),\n",
    "            StructField(\"engaging_follow_diff_log_ss_num\",DoubleType),\n",
    "            StructField(\"engaged_follower_diff_engaging_following_log_ss_num\",DoubleType),\n",
    "            StructField(\"engaged_following_diff_engaging_follower_log_ss_num\",DoubleType),\n",
    "            StructField(\"engaged_with_user_follower_count_log_ss_num\",DoubleType),\n",
    "            StructField(\"engaging_user_follower_count_log_ss_num\",DoubleType),\n",
    "            StructField(\"engaged_with_user_following_count_log_ss_num\",DoubleType),\n",
    "            StructField(\"engaging_user_following_count_log_ss_num\",DoubleType),\n",
    "            StructField(\"PhotoCount_num\",IntegerType),\n",
    "            StructField(\"VideoCount_num\",IntegerType),\n",
    "            StructField(\"GIFCount_num\",IntegerType),\n",
    "            StructField(\"linkCount_num\",IntegerType),\n",
    "            StructField(\"engaged_with_user_follower_count_q_cat\",DoubleType),\n",
    "            StructField(\"engaged_with_user_following_count_q_cat\",DoubleType),\n",
    "            StructField(\"engaged_with_user_account_creation_q_cat\",DoubleType),\n",
    "            StructField(\"engaging_user_follower_count_q_cat\",DoubleType),\n",
    "            StructField(\"engaging_user_following_count_q_cat\",DoubleType),\n",
    "            StructField(\"engaging_user_account_creation_q_cat\",DoubleType),\n",
    "            StructField(\"total_appearance_num\",LongType),\n",
    "            StructField(\"perc_n_interactions_num\",DoubleType),\n",
    "            StructField(\"perc_n_commented_num\",DoubleType),\n",
    "            StructField(\"perc_n_liked_num\",DoubleType),\n",
    "            StructField(\"perc_n_replied_num\",DoubleType),\n",
    "            StructField(\"perc_n_retweeted_num\",DoubleType),\n",
    "            StructField(\"indicator_reply\",IntegerType),\n",
    "            StructField(\"indicator_retweet\",IntegerType),\n",
    "            StructField(\"indicator_retweet_with_comment\",IntegerType),\n",
    "            StructField(\"indicator_like\",IntegerType),\n",
    "            StructField(\"indicator_interaction\",IntegerType)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
